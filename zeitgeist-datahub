#! /usr/bin/env python
# -.- encoding: utf-8 -.-

import sys
import os
import glob
import gettext
import logging
import gobject
import dbus.exceptions

from zeitgeist import config
from zeitgeist.loggers.zeitgeist_setup_service import DataProviderService

gettext.install("zeitgeist", config.localedir, unicode=1)
logging.basicConfig(level=logging.DEBUG)

installation_dir = os.path.dirname(os.path.realpath(config.__file__))
datasource_dir = os.path.join(installation_dir, "loggers/datasources")
sys.path.append(datasource_dir)

from zeitgeist.dbusutils import *

class DataHub(gobject.GObject):
	
	__gsignals__ = {
		"reload" : (gobject.SIGNAL_RUN_LAST, gobject.TYPE_NONE, ()),
	}
	
	def __init__(self):
		
		gobject.GObject.__init__(self)
		dbus_connect("SignalExit", self._daemon_exit)
		
		self._client = get_engine_interface()
		
		# Load the data sources
		self._sources = []
		for datasource_file in glob.glob(datasource_dir + '/*.py'):
			self._load_datasource_file(os.path.basename(datasource_file))
		
		# Start by fetch new items from all sources
		self._sources_queue = list(self._sources)
		if not self._sources_queue:
			logging.warning(_("No passive loggers found, bye."))
			sys.exit(1) # Mainloop doesn't exit yet, exit directly
		self._db_update_in_progress = True
		gobject.idle_add(self._update_db_async)
		
		for source in self._sources:
			source.connect("reload", self._update_db_with_source)
		
		self._mainloop = gobject.MainLoop()
		self.dbus_service = DataProviderService(self._sources, None)
		self._mainloop.run()
	
	def _daemon_exit(self):
		self._mainloop.quit()
	
	def _load_datasource_file(self, datasource_file):
		
		try:
			datasource_object = __import__(datasource_file[:-3])
		except ImportError, err:
			logging.exception(_("Could not load file: %s" % datasource_file))
			return False
		
		if hasattr(datasource_object, "__datasource__"):
			object = datasource_object.__datasource__
			if hasattr(object, "__iter__"):
				self._sources.extend(object)
			else:
				self._sources.append(object)
	
	def _update_db_with_source(self, source):
		"""
		Add new items into the database. This funcion should not be
		called directly, but instead activated through the "reload"
		signal.
		"""
		
		if not source in self._sources_queue:
			self._sources_queue.append(source)
			if not self._db_update_in_progress:
				self._db_update_in_progress = True
				gobject.idle_add(self._update_db_async)
	
	def _update_db_async(self):
		
		logging.debug(_("Updating database with new %s items") % \
			self._sources_queue[0].get_name())
		
		items = set()
		for num, item in enumerate(self._sources_queue[0].get_items()):
			items.add(plainify_dict(item))
			if num % 200 == 0:
				self._insert_items(self._sources_queue[0].get_name(), items)
				items = set()
		if items:
			self._insert_items(self._sources_queue[0].get_name(), items)
 		
 		del self._sources_queue[0]
		
		if len(self._sources_queue) == 0:
			self._db_update_in_progress = False
			return False # Return False to stop this callback
		
		# Otherwise, if there are more items in the queue return True so
		# that GTK+ will continue to call this function in idle CPU time
		return True
	
	def _insert_items(self, source_name, items):
		if items:
			try:
				self._client.InsertItems(items)
			except dbus.exceptions.DBusException, error:
				error = error.get_dbus_name()
				if error == "org.freedesktop.DBus.Error.ServiceUnknown":
					self._daemon_exit()
				else:
					raise
			except TypeError, error:
				logging.exception(_("Type error logging item from \"%s\": %s" % \
					(source_name, error)))

datahub = DataHub()
